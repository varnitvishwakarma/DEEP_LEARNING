{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varnitvishwakarma/DEEP_LEARNING/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCvlYUCRkfMa"
      },
      "source": [
        "# PyTorch Basics: Tensors & Gradients\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" width=\"600\"\n",
        "     height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "  PyTorch is an open-source machine learning framework that is primarily used for developing and training deep learning models. It was developed by Facebook's AI Research Lab and released in 2016. PyTorch provides a flexible and dynamic approach to building neural networks, making it a popular choice among researchers and developers.\n",
        "\n",
        "The framework is built on a dynamic computational graph concept, which means that the graph is built and modified on-the-fly as the program runs. This allows for more intuitive and flexible model development, as you can use standard Python control flow statements and debug the model easily.\n",
        "\n",
        "PyTorch supports automatic differentiation, which enables efficient computation of gradients for training neural networks using backpropagation. It provides a rich set of tools and libraries for tasks such as data loading, model building, optimization, and evaluation.\n",
        "\n",
        "One of the key advantages of PyTorch is its support for GPU acceleration, allowing you to train models on GPUs to significantly speed up computations. It also has a large and active community, which means there are plenty of resources, tutorials, and pre-trained models available.\n",
        "\n",
        "PyTorch is often compared to TensorFlow, another popular deep learning framework. While TensorFlow focuses more on static computation graphs, PyTorch emphasizes dynamic computation graphs. This fundamental difference in design philosophy gives PyTorch an edge when it comes to flexibility and ease of use.\n",
        "\n",
        "Overall, PyTorch is widely used in the research community and is gaining popularity in industry applications as well. It provides a powerful and user-friendly platform for building and training deep learning models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5zufMMCkfMo"
      },
      "source": [
        "## installation\n",
        "\n",
        "installation instructions here: https://pytorch.org ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmnQZPSxkfMp"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P18JcOiokfMr"
      },
      "source": [
        "Let's import the `torch` module to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DGo8nxo7kfMs"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqVgPkfKkfMt"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HUtf5elpkfMv",
        "outputId": "f76a7ac3-17d6-4ed9-8ed6-13984792feb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIB1GJlakfMw"
      },
      "source": [
        "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jz-QWm7NkfMx",
        "outputId": "9b0587a5-3d05-4de2-c723-63fb283dac69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "t1.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_-gGY-kfMy"
      },
      "source": [
        "Let's try creating more complex tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jIn2pRzLkfMz",
        "outputId": "d9561ebe-abd9-4660-a7eb-1ede25e2f96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KdQsBZqukfM0",
        "outputId": "b31735ee-6311-436d-ff1e-49eec50f6a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0yZHb2E5kfM0",
        "outputId": "f5f01feb-4efc-4261-c3c6-43947b3ca9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11., 12., 13.],\n",
              "         [13., 14., 15.]],\n",
              "\n",
              "        [[15., 16., 17.],\n",
              "         [17., 18., 19.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "     [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "     [17, 18, 19.]]])\n",
        "t4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS8_bliOkfM1"
      },
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PUx8_FbXkfM1",
        "outputId": "ce5d65aa-ba3f-459d-8e2a-1040ed7e87ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print(t1)\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CeRzfymnkfM2",
        "outputId": "8e042c39-e91e-489d-93f5-5102af4c0da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print(t2)\n",
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NXvIYzuxkfM2",
        "outputId": "2b2e2933-7529-4aa3-bc22-cd4619aa4ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print(t3)\n",
        "t3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p5okplTtkfM3",
        "outputId": "437f9b29-19f5-437f-c135-fe1b0d27da14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print(t4)\n",
        "t4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NOD0XtokfM3"
      },
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZiaIlFtWkfM4",
        "outputId": "91e20299-63d2-4eaf-c210-e38339dea8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 3 at dim 1 (got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-83912cf67c5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    [9, 10]])\n\u001b[1;32m      5\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
          ]
        }
      ],
      "source": [
        "# Matrix\n",
        "t5 = torch.tensor([[5., 6, 11],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBdhA9kkfM4"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n",
        "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cKJKdakfM5"
      },
      "source": [
        "## Tensor operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lj6TfIlokfM5",
        "outputId": "623e5abe-ccf4-4b57-a509-560e6eef82cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZlcATrkfM5"
      },
      "source": [
        "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
        "\n",
        "Let's create a new tensor `y` by combining these tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IKcsAaE0kfM6",
        "outputId": "0f7731ab-5f5a-4dce-ffea-6ee1dede42dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNV4U0-OkfM6"
      },
      "source": [
        "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
        "\n",
        "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0RVH2vHCkfM6"
      },
      "outputs": [],
      "source": [
        "# Compute derivatives\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHyHerbekfM7"
      },
      "source": [
        "The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_zTB-VUqkfM7",
        "outputId": "89784d05-9835-4c75-fd89-7f0709a43bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad"
      ],
      "metadata": {
        "id": "ScSgDiJX_61L",
        "outputId": "0c666740-6a1e-4d8f-d477-1f50e90c37ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvGfw6PJkfM7"
      },
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvR-LWzgkfM8"
      },
      "source": [
        "## Tensor functions\n",
        "\n",
        "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gi5eISBckfM8",
        "outputId": "646878d1-d6c1-4e9f-e918-969e3bf299b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3"
      ],
      "metadata": {
        "id": "mn8hlrV7AWMs",
        "outputId": "04ddd45b-1259-484e-9f81-e3bd8562663c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "caAPy-P7kfM8",
        "outputId": "86055c47-bfaa-4ec5-95ed-38c193a9cf20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Concatenate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7.shape"
      ],
      "metadata": {
        "id": "NqLwf1dSAg63",
        "outputId": "0cd78d05-2632-4322-f8f6-264eaa63f15c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RHmUkGOHkfM9",
        "outputId": "6fbeb48d-d642-4b6f-b3d9-3312fbf525eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Compute the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K9UFIgc-kfM9",
        "outputId": "d653e3b5-0031-4683-a1ee-f4244201f053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Change the shape of a tensor\n",
        "t9 = t8.reshape(3, 2, 2)\n",
        "t9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t10=t8.reshape(2,6)\n",
        "t10"
      ],
      "metadata": {
        "id": "Kc3VYNSXArhf",
        "outputId": "0c6b733f-c050-4a26-a81b-0dd9206de5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794,  0.6570,  0.9894,  0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165, -0.9165, -0.9165, -0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK9aNsnkfM9"
      },
      "source": [
        "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36942dZpkfM-"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKH8QMxDkfM-"
      },
      "source": [
        "Here's how we create an array in Numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XlCWcXUckfM_",
        "outputId": "3769db5f-95c8-4244-b3b5-ee535b41e90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.]])\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-UeD40kfM_"
      },
      "source": [
        "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DaPUjIiokfNB",
        "outputId": "16cae38e-337e-454a-dec0-018a2e5a4e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-kN6vp4kfNC"
      },
      "source": [
        "Let's verify that the numpy array and torch tensor have similar data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KL76Ma8ekfND",
        "outputId": "6fda1e2f-b5b2-416e-aa0e-38d64b9dab1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "x.dtype, y.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vuHKXXkfNE"
      },
      "source": [
        "We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OEBugCySkfNE",
        "outputId": "8124b26d-a0f5-487c-a40b-5accb467285a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Convert a torch tensor to a numpy array\n",
        "z = y.numpy()\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgxySGeWkfNE"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear-regression from scrach using pytorch\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "GPb963Lz5laq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "elamAaJH5tYF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making training data\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "Ze7LRltk5tUV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "ars5xesW5tRt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert input and target to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92TqO635tPO",
        "outputId": "765215b5-6594-407b-974e-0f1cddc611bd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_2iaph5tMh",
        "outputId": "63ffe029-16d5-4980-a3ef-fdea3fa6e793"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6122,  0.9153, -0.5778],\n",
            "        [ 0.7672, -0.4849, -0.9879]], requires_grad=True)\n",
            "tensor([ 0.9884, -0.9399], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "ZHqEIQKU56cs"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9J__d3l56Ze",
        "outputId": "8d7ce910-f08c-4e07-be55-42557381f16a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[155.1587, -19.9013],\n",
            "        [191.2656, -37.0202],\n",
            "        [230.3889, -56.4659],\n",
            "        [183.4112,  19.9121],\n",
            "        [159.6531, -63.7051]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actual\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV0XrG2k56Xf",
        "outputId": "c449b618-30eb-4ee0-b154-e306d241d31c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function MSE\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "vlr1NKsC56Ts"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQJRKGXP56RJ",
        "outputId": "f8f0ac4b-78b8-4481-9095-0d5e7d0a74ad"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16036.3906, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "iGypGOsF56Oi"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRT4IVP56Lu",
        "outputId": "f762a53e-6e14-4bd0-83d8-f52842764148"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6122,  0.9153, -0.5778],\n",
            "        [ 0.7672, -0.4849, -0.9879]], requires_grad=True) \n",
            "\n",
            "tensor([[  9467.3193,   8730.5010,   5543.8628],\n",
            "        [ -9991.1582, -12366.4141,  -7421.9375]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWMcsxjz6IBr",
        "outputId": "246cc9b6-a9c5-4aa6-a0ab-71d0ab0e94b9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9884, -0.9399], requires_grad=True) \n",
            "\n",
            "tensor([ 107.7755, -123.4361])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdeYBsU6H-6",
        "outputId": "0d2fced7-2a44-463f-abc6-34a931ef818e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIbBPr-x6H8l",
        "outputId": "c5cd2662-0525-4924-a943-d1451ea59b8a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[155.1587, -19.9013],\n",
            "        [191.2656, -37.0202],\n",
            "        [230.3889, -56.4659],\n",
            "        [183.4112,  19.9121],\n",
            "        [159.6531, -63.7051]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEOGA0cy6PzN",
        "outputId": "ae7c6153-5922-40ff-c107-6d6991dd5a87"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16036.3906, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du5TIt2e6Pwg",
        "outputId": "6521083a-d0c3-4753-f669-20a7c4543d49"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  9467.3193,   8730.5010,   5543.8628],\n",
            "        [ -9991.1582, -12366.4141,  -7421.9375]]) \n",
            "\n",
            "tensor([ 107.7755, -123.4361])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "Jx0SBLV56PtU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD2CAdtn6Pq2",
        "outputId": "a8999d24-d116-44d1-94b1-072330304875"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.5175,  0.8280, -0.6333],\n",
            "        [ 0.8671, -0.3612, -0.9137]], requires_grad=True)\n",
            "tensor([ 0.9873, -0.9387], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate again\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT-GtGY6Xzq",
        "outputId": "7da90d1f-f32a-4395-a1b9-1145a44acebf"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11441.6162, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "     w -= w.grad * 1e-5 # learning rate\n",
        "     b -= b.grad * 1e-5\n",
        "     w.grad.zero_()\n",
        "     b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijRMFN3C6Xv1",
        "outputId": "b655f737-48c6-40dc-80bc-a38414465c4c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 11441.6162109375\n",
            "Epochs(1/100) & Loss 8338.0390625\n",
            "Epochs(2/100) & Loss 6239.4443359375\n",
            "Epochs(3/100) & Loss 4818.18359375\n",
            "Epochs(4/100) & Loss 3853.454345703125\n",
            "Epochs(5/100) & Loss 3196.463134765625\n",
            "Epochs(6/100) & Loss 2746.936767578125\n",
            "Epochs(7/100) & Loss 2437.3017578125\n",
            "Epochs(8/100) & Loss 2222.021240234375\n",
            "Epochs(9/100) & Loss 2070.4072265625\n",
            "Epochs(10/100) & Loss 1961.7783203125\n",
            "Epochs(11/100) & Loss 1882.196533203125\n",
            "Epochs(12/100) & Loss 1822.2679443359375\n",
            "Epochs(13/100) & Loss 1775.661376953125\n",
            "Epochs(14/100) & Loss 1738.1097412109375\n",
            "Epochs(15/100) & Loss 1706.7366943359375\n",
            "Epochs(16/100) & Loss 1679.601806640625\n",
            "Epochs(17/100) & Loss 1655.397216796875\n",
            "Epochs(18/100) & Loss 1633.2408447265625\n",
            "Epochs(19/100) & Loss 1612.53759765625\n",
            "Epochs(20/100) & Loss 1592.8841552734375\n",
            "Epochs(21/100) & Loss 1574.0091552734375\n",
            "Epochs(22/100) & Loss 1555.7286376953125\n",
            "Epochs(23/100) & Loss 1537.916748046875\n",
            "Epochs(24/100) & Loss 1520.4898681640625\n",
            "Epochs(25/100) & Loss 1503.3885498046875\n",
            "Epochs(26/100) & Loss 1486.5732421875\n",
            "Epochs(27/100) & Loss 1470.015869140625\n",
            "Epochs(28/100) & Loss 1453.697021484375\n",
            "Epochs(29/100) & Loss 1437.602783203125\n",
            "Epochs(30/100) & Loss 1421.72265625\n",
            "Epochs(31/100) & Loss 1406.049560546875\n",
            "Epochs(32/100) & Loss 1390.576416015625\n",
            "Epochs(33/100) & Loss 1375.2991943359375\n",
            "Epochs(34/100) & Loss 1360.214111328125\n",
            "Epochs(35/100) & Loss 1345.3170166015625\n",
            "Epochs(36/100) & Loss 1330.60546875\n",
            "Epochs(37/100) & Loss 1316.0765380859375\n",
            "Epochs(38/100) & Loss 1301.7275390625\n",
            "Epochs(39/100) & Loss 1287.555419921875\n",
            "Epochs(40/100) & Loss 1273.558837890625\n",
            "Epochs(41/100) & Loss 1259.734619140625\n",
            "Epochs(42/100) & Loss 1246.0810546875\n",
            "Epochs(43/100) & Loss 1232.5958251953125\n",
            "Epochs(44/100) & Loss 1219.2767333984375\n",
            "Epochs(45/100) & Loss 1206.121826171875\n",
            "Epochs(46/100) & Loss 1193.128662109375\n",
            "Epochs(47/100) & Loss 1180.2955322265625\n",
            "Epochs(48/100) & Loss 1167.6204833984375\n",
            "Epochs(49/100) & Loss 1155.1011962890625\n",
            "Epochs(50/100) & Loss 1142.735595703125\n",
            "Epochs(51/100) & Loss 1130.522216796875\n",
            "Epochs(52/100) & Loss 1118.459228515625\n",
            "Epochs(53/100) & Loss 1106.544189453125\n",
            "Epochs(54/100) & Loss 1094.775390625\n",
            "Epochs(55/100) & Loss 1083.151123046875\n",
            "Epochs(56/100) & Loss 1071.6697998046875\n",
            "Epochs(57/100) & Loss 1060.3291015625\n",
            "Epochs(58/100) & Loss 1049.127685546875\n",
            "Epochs(59/100) & Loss 1038.063720703125\n",
            "Epochs(60/100) & Loss 1027.1353759765625\n",
            "Epochs(61/100) & Loss 1016.3409423828125\n",
            "Epochs(62/100) & Loss 1005.6788330078125\n",
            "Epochs(63/100) & Loss 995.1470947265625\n",
            "Epochs(64/100) & Loss 984.7442626953125\n",
            "Epochs(65/100) & Loss 974.4689331054688\n",
            "Epochs(66/100) & Loss 964.3192138671875\n",
            "Epochs(67/100) & Loss 954.2937622070312\n",
            "Epochs(68/100) & Loss 944.3909301757812\n",
            "Epochs(69/100) & Loss 934.6091918945312\n",
            "Epochs(70/100) & Loss 924.9468994140625\n",
            "Epochs(71/100) & Loss 915.4027099609375\n",
            "Epochs(72/100) & Loss 905.9749145507812\n",
            "Epochs(73/100) & Loss 896.6624755859375\n",
            "Epochs(74/100) & Loss 887.46337890625\n",
            "Epochs(75/100) & Loss 878.3766479492188\n",
            "Epochs(76/100) & Loss 869.4006958007812\n",
            "Epochs(77/100) & Loss 860.5340576171875\n",
            "Epochs(78/100) & Loss 851.7755737304688\n",
            "Epochs(79/100) & Loss 843.1238403320312\n",
            "Epochs(80/100) & Loss 834.5772705078125\n",
            "Epochs(81/100) & Loss 826.1350708007812\n",
            "Epochs(82/100) & Loss 817.7951049804688\n",
            "Epochs(83/100) & Loss 809.5565795898438\n",
            "Epochs(84/100) & Loss 801.4185180664062\n",
            "Epochs(85/100) & Loss 793.3792114257812\n",
            "Epochs(86/100) & Loss 785.4376220703125\n",
            "Epochs(87/100) & Loss 777.5923461914062\n",
            "Epochs(88/100) & Loss 769.8421630859375\n",
            "Epochs(89/100) & Loss 762.1860961914062\n",
            "Epochs(90/100) & Loss 754.623046875\n",
            "Epochs(91/100) & Loss 747.1513671875\n",
            "Epochs(92/100) & Loss 739.7703857421875\n",
            "Epochs(93/100) & Loss 732.4786376953125\n",
            "Epochs(94/100) & Loss 725.2753295898438\n",
            "Epochs(95/100) & Loss 718.1592407226562\n",
            "Epochs(96/100) & Loss 711.1290893554688\n",
            "Epochs(97/100) & Loss 704.1838989257812\n",
            "Epochs(98/100) & Loss 697.3226928710938\n",
            "Epochs(99/100) & Loss 690.5443115234375\n",
            "Epochs(100/100) & Loss 683.84765625\n",
            "Epochs(101/100) & Loss 677.23193359375\n",
            "Epochs(102/100) & Loss 670.6959228515625\n",
            "Epochs(103/100) & Loss 664.23876953125\n",
            "Epochs(104/100) & Loss 657.859375\n",
            "Epochs(105/100) & Loss 651.5567016601562\n",
            "Epochs(106/100) & Loss 645.330078125\n",
            "Epochs(107/100) & Loss 639.17822265625\n",
            "Epochs(108/100) & Loss 633.1004028320312\n",
            "Epochs(109/100) & Loss 627.0955810546875\n",
            "Epochs(110/100) & Loss 621.1629028320312\n",
            "Epochs(111/100) & Loss 615.3014526367188\n",
            "Epochs(112/100) & Loss 609.5101318359375\n",
            "Epochs(113/100) & Loss 603.7886962890625\n",
            "Epochs(114/100) & Loss 598.1355590820312\n",
            "Epochs(115/100) & Loss 592.5502319335938\n",
            "Epochs(116/100) & Loss 587.03173828125\n",
            "Epochs(117/100) & Loss 581.5792236328125\n",
            "Epochs(118/100) & Loss 576.1919555664062\n",
            "Epochs(119/100) & Loss 570.8689575195312\n",
            "Epochs(120/100) & Loss 565.6097412109375\n",
            "Epochs(121/100) & Loss 560.4132080078125\n",
            "Epochs(122/100) & Loss 555.2786865234375\n",
            "Epochs(123/100) & Loss 550.205322265625\n",
            "Epochs(124/100) & Loss 545.1925048828125\n",
            "Epochs(125/100) & Loss 540.2394409179688\n",
            "Epochs(126/100) & Loss 535.34521484375\n",
            "Epochs(127/100) & Loss 530.50927734375\n",
            "Epochs(128/100) & Loss 525.7307739257812\n",
            "Epochs(129/100) & Loss 521.009033203125\n",
            "Epochs(130/100) & Loss 516.3434448242188\n",
            "Epochs(131/100) & Loss 511.733154296875\n",
            "Epochs(132/100) & Loss 507.1775817871094\n",
            "Epochs(133/100) & Loss 502.67584228515625\n",
            "Epochs(134/100) & Loss 498.2275390625\n",
            "Epochs(135/100) & Loss 493.831787109375\n",
            "Epochs(136/100) & Loss 489.4881286621094\n",
            "Epochs(137/100) & Loss 485.19573974609375\n",
            "Epochs(138/100) & Loss 480.9540100097656\n",
            "Epochs(139/100) & Loss 476.7622985839844\n",
            "Epochs(140/100) & Loss 472.62017822265625\n",
            "Epochs(141/100) & Loss 468.52667236328125\n",
            "Epochs(142/100) & Loss 464.4815979003906\n",
            "Epochs(143/100) & Loss 460.48388671875\n",
            "Epochs(144/100) & Loss 456.53338623046875\n",
            "Epochs(145/100) & Loss 452.62921142578125\n",
            "Epochs(146/100) & Loss 448.7709045410156\n",
            "Epochs(147/100) & Loss 444.9579162597656\n",
            "Epochs(148/100) & Loss 441.1896057128906\n",
            "Epochs(149/100) & Loss 437.46527099609375\n",
            "Epochs(150/100) & Loss 433.7847595214844\n",
            "Epochs(151/100) & Loss 430.1470642089844\n",
            "Epochs(152/100) & Loss 426.5521545410156\n",
            "Epochs(153/100) & Loss 422.9990234375\n",
            "Epochs(154/100) & Loss 419.48736572265625\n",
            "Epochs(155/100) & Loss 416.0167541503906\n",
            "Epochs(156/100) & Loss 412.5865173339844\n",
            "Epochs(157/100) & Loss 409.1961364746094\n",
            "Epochs(158/100) & Loss 405.84527587890625\n",
            "Epochs(159/100) & Loss 402.53326416015625\n",
            "Epochs(160/100) & Loss 399.25982666015625\n",
            "Epochs(161/100) & Loss 396.0242614746094\n",
            "Epochs(162/100) & Loss 392.8262634277344\n",
            "Epochs(163/100) & Loss 389.665283203125\n",
            "Epochs(164/100) & Loss 386.5408630371094\n",
            "Epochs(165/100) & Loss 383.45245361328125\n",
            "Epochs(166/100) & Loss 380.39984130859375\n",
            "Epochs(167/100) & Loss 377.3824462890625\n",
            "Epochs(168/100) & Loss 374.39984130859375\n",
            "Epochs(169/100) & Loss 371.45147705078125\n",
            "Epochs(170/100) & Loss 368.53704833984375\n",
            "Epochs(171/100) & Loss 365.65625\n",
            "Epochs(172/100) & Loss 362.8085021972656\n",
            "Epochs(173/100) & Loss 359.99334716796875\n",
            "Epochs(174/100) & Loss 357.21044921875\n",
            "Epochs(175/100) & Loss 354.45941162109375\n",
            "Epochs(176/100) & Loss 351.73992919921875\n",
            "Epochs(177/100) & Loss 349.0514221191406\n",
            "Epochs(178/100) & Loss 346.3936767578125\n",
            "Epochs(179/100) & Loss 343.7662048339844\n",
            "Epochs(180/100) & Loss 341.16864013671875\n",
            "Epochs(181/100) & Loss 338.6007080078125\n",
            "Epochs(182/100) & Loss 336.06195068359375\n",
            "Epochs(183/100) & Loss 333.55194091796875\n",
            "Epochs(184/100) & Loss 331.070556640625\n",
            "Epochs(185/100) & Loss 328.6171875\n",
            "Epochs(186/100) & Loss 326.19158935546875\n",
            "Epochs(187/100) & Loss 323.79345703125\n",
            "Epochs(188/100) & Loss 321.4223937988281\n",
            "Epochs(189/100) & Loss 319.07806396484375\n",
            "Epochs(190/100) & Loss 316.76007080078125\n",
            "Epochs(191/100) & Loss 314.4683532714844\n",
            "Epochs(192/100) & Loss 312.2023010253906\n",
            "Epochs(193/100) & Loss 309.961669921875\n",
            "Epochs(194/100) & Loss 307.74615478515625\n",
            "Epochs(195/100) & Loss 305.55548095703125\n",
            "Epochs(196/100) & Loss 303.3893737792969\n",
            "Epochs(197/100) & Loss 301.24737548828125\n",
            "Epochs(198/100) & Loss 299.1293029785156\n",
            "Epochs(199/100) & Loss 297.0350036621094\n",
            "Epochs(200/100) & Loss 294.96380615234375\n",
            "Epochs(201/100) & Loss 292.9156799316406\n",
            "Epochs(202/100) & Loss 290.89031982421875\n",
            "Epochs(203/100) & Loss 288.88751220703125\n",
            "Epochs(204/100) & Loss 286.9068298339844\n",
            "Epochs(205/100) & Loss 284.9480895996094\n",
            "Epochs(206/100) & Loss 283.01092529296875\n",
            "Epochs(207/100) & Loss 281.09527587890625\n",
            "Epochs(208/100) & Loss 279.2005310058594\n",
            "Epochs(209/100) & Loss 277.3267822265625\n",
            "Epochs(210/100) & Loss 275.47357177734375\n",
            "Epochs(211/100) & Loss 273.64068603515625\n",
            "Epochs(212/100) & Loss 271.8279113769531\n",
            "Epochs(213/100) & Loss 270.0349426269531\n",
            "Epochs(214/100) & Loss 268.2615661621094\n",
            "Epochs(215/100) & Loss 266.5075378417969\n",
            "Epochs(216/100) & Loss 264.77264404296875\n",
            "Epochs(217/100) & Loss 263.0566711425781\n",
            "Epochs(218/100) & Loss 261.3594055175781\n",
            "Epochs(219/100) & Loss 259.680419921875\n",
            "Epochs(220/100) & Loss 258.01959228515625\n",
            "Epochs(221/100) & Loss 256.3768615722656\n",
            "Epochs(222/100) & Loss 254.7517852783203\n",
            "Epochs(223/100) & Loss 253.14419555664062\n",
            "Epochs(224/100) & Loss 251.5540008544922\n",
            "Epochs(225/100) & Loss 249.98080444335938\n",
            "Epochs(226/100) & Loss 248.4246368408203\n",
            "Epochs(227/100) & Loss 246.885009765625\n",
            "Epochs(228/100) & Loss 245.36196899414062\n",
            "Epochs(229/100) & Loss 243.85507202148438\n",
            "Epochs(230/100) & Loss 242.36434936523438\n",
            "Epochs(231/100) & Loss 240.8894500732422\n",
            "Epochs(232/100) & Loss 239.4302520751953\n",
            "Epochs(233/100) & Loss 237.98660278320312\n",
            "Epochs(234/100) & Loss 236.5581512451172\n",
            "Epochs(235/100) & Loss 235.1448211669922\n",
            "Epochs(236/100) & Loss 233.7463836669922\n",
            "Epochs(237/100) & Loss 232.3627166748047\n",
            "Epochs(238/100) & Loss 230.9936981201172\n",
            "Epochs(239/100) & Loss 229.638916015625\n",
            "Epochs(240/100) & Loss 228.2983856201172\n",
            "Epochs(241/100) & Loss 226.9719696044922\n",
            "Epochs(242/100) & Loss 225.65927124023438\n",
            "Epochs(243/100) & Loss 224.36038208007812\n",
            "Epochs(244/100) & Loss 223.07498168945312\n",
            "Epochs(245/100) & Loss 221.8029022216797\n",
            "Epochs(246/100) & Loss 220.5439453125\n",
            "Epochs(247/100) & Loss 219.2981719970703\n",
            "Epochs(248/100) & Loss 218.06515502929688\n",
            "Epochs(249/100) & Loss 216.8450164794922\n",
            "Epochs(250/100) & Loss 215.6372528076172\n",
            "Epochs(251/100) & Loss 214.44198608398438\n",
            "Epochs(252/100) & Loss 213.25894165039062\n",
            "Epochs(253/100) & Loss 212.08798217773438\n",
            "Epochs(254/100) & Loss 210.92904663085938\n",
            "Epochs(255/100) & Loss 209.7819061279297\n",
            "Epochs(256/100) & Loss 208.64633178710938\n",
            "Epochs(257/100) & Loss 207.52243041992188\n",
            "Epochs(258/100) & Loss 206.4098663330078\n",
            "Epochs(259/100) & Loss 205.30856323242188\n",
            "Epochs(260/100) & Loss 204.21835327148438\n",
            "Epochs(261/100) & Loss 203.13906860351562\n",
            "Epochs(262/100) & Loss 202.07070922851562\n",
            "Epochs(263/100) & Loss 201.0130615234375\n",
            "Epochs(264/100) & Loss 199.96592712402344\n",
            "Epochs(265/100) & Loss 198.9292449951172\n",
            "Epochs(266/100) & Loss 197.90304565429688\n",
            "Epochs(267/100) & Loss 196.88681030273438\n",
            "Epochs(268/100) & Loss 195.8807373046875\n",
            "Epochs(269/100) & Loss 194.88461303710938\n",
            "Epochs(270/100) & Loss 193.89840698242188\n",
            "Epochs(271/100) & Loss 192.92189025878906\n",
            "Epochs(272/100) & Loss 191.9549102783203\n",
            "Epochs(273/100) & Loss 190.9973907470703\n",
            "Epochs(274/100) & Loss 190.04930114746094\n",
            "Epochs(275/100) & Loss 189.1104278564453\n",
            "Epochs(276/100) & Loss 188.1807098388672\n",
            "Epochs(277/100) & Loss 187.2600555419922\n",
            "Epochs(278/100) & Loss 186.34823608398438\n",
            "Epochs(279/100) & Loss 185.4453125\n",
            "Epochs(280/100) & Loss 184.55105590820312\n",
            "Epochs(281/100) & Loss 183.66549682617188\n",
            "Epochs(282/100) & Loss 182.7882843017578\n",
            "Epochs(283/100) & Loss 181.9195556640625\n",
            "Epochs(284/100) & Loss 181.0591278076172\n",
            "Epochs(285/100) & Loss 180.2068634033203\n",
            "Epochs(286/100) & Loss 179.36276245117188\n",
            "Epochs(287/100) & Loss 178.52658081054688\n",
            "Epochs(288/100) & Loss 177.69833374023438\n",
            "Epochs(289/100) & Loss 176.8778839111328\n",
            "Epochs(290/100) & Loss 176.0651092529297\n",
            "Epochs(291/100) & Loss 175.26007080078125\n",
            "Epochs(292/100) & Loss 174.4625244140625\n",
            "Epochs(293/100) & Loss 173.67242431640625\n",
            "Epochs(294/100) & Loss 172.88961791992188\n",
            "Epochs(295/100) & Loss 172.1141357421875\n",
            "Epochs(296/100) & Loss 171.3457489013672\n",
            "Epochs(297/100) & Loss 170.5846405029297\n",
            "Epochs(298/100) & Loss 169.83035278320312\n",
            "Epochs(299/100) & Loss 169.08302307128906\n",
            "Epochs(300/100) & Loss 168.3425750732422\n",
            "Epochs(301/100) & Loss 167.60897827148438\n",
            "Epochs(302/100) & Loss 166.88194274902344\n",
            "Epochs(303/100) & Loss 166.16140747070312\n",
            "Epochs(304/100) & Loss 165.44754028320312\n",
            "Epochs(305/100) & Loss 164.7401123046875\n",
            "Epochs(306/100) & Loss 164.0391082763672\n",
            "Epochs(307/100) & Loss 163.34426879882812\n",
            "Epochs(308/100) & Loss 162.65565490722656\n",
            "Epochs(309/100) & Loss 161.97329711914062\n",
            "Epochs(310/100) & Loss 161.29684448242188\n",
            "Epochs(311/100) & Loss 160.6265106201172\n",
            "Epochs(312/100) & Loss 159.96209716796875\n",
            "Epochs(313/100) & Loss 159.30345153808594\n",
            "Epochs(314/100) & Loss 158.6507568359375\n",
            "Epochs(315/100) & Loss 158.0035858154297\n",
            "Epochs(316/100) & Loss 157.36219787597656\n",
            "Epochs(317/100) & Loss 156.72634887695312\n",
            "Epochs(318/100) & Loss 156.09600830078125\n",
            "Epochs(319/100) & Loss 155.47116088867188\n",
            "Epochs(320/100) & Loss 154.85166931152344\n",
            "Epochs(321/100) & Loss 154.2376251220703\n",
            "Epochs(322/100) & Loss 153.6286163330078\n",
            "Epochs(323/100) & Loss 153.02499389648438\n",
            "Epochs(324/100) & Loss 152.42648315429688\n",
            "Epochs(325/100) & Loss 151.83294677734375\n",
            "Epochs(326/100) & Loss 151.24449157714844\n",
            "Epochs(327/100) & Loss 150.6610565185547\n",
            "Epochs(328/100) & Loss 150.0825653076172\n",
            "Epochs(329/100) & Loss 149.50875854492188\n",
            "Epochs(330/100) & Loss 148.93988037109375\n",
            "Epochs(331/100) & Loss 148.37571716308594\n",
            "Epochs(332/100) & Loss 147.81614685058594\n",
            "Epochs(333/100) & Loss 147.26119995117188\n",
            "Epochs(334/100) & Loss 146.71099853515625\n",
            "Epochs(335/100) & Loss 146.16525268554688\n",
            "Epochs(336/100) & Loss 145.6238555908203\n",
            "Epochs(337/100) & Loss 145.08688354492188\n",
            "Epochs(338/100) & Loss 144.55441284179688\n",
            "Epochs(339/100) & Loss 144.02615356445312\n",
            "Epochs(340/100) & Loss 143.50205993652344\n",
            "Epochs(341/100) & Loss 142.9822998046875\n",
            "Epochs(342/100) & Loss 142.46676635742188\n",
            "Epochs(343/100) & Loss 141.95529174804688\n",
            "Epochs(344/100) & Loss 141.44790649414062\n",
            "Epochs(345/100) & Loss 140.9445037841797\n",
            "Epochs(346/100) & Loss 140.4449920654297\n",
            "Epochs(347/100) & Loss 139.9495849609375\n",
            "Epochs(348/100) & Loss 139.4579315185547\n",
            "Epochs(349/100) & Loss 138.9701690673828\n",
            "Epochs(350/100) & Loss 138.4862823486328\n",
            "Epochs(351/100) & Loss 138.0059814453125\n",
            "Epochs(352/100) & Loss 137.52947998046875\n",
            "Epochs(353/100) & Loss 137.05661010742188\n",
            "Epochs(354/100) & Loss 136.58737182617188\n",
            "Epochs(355/100) & Loss 136.12173461914062\n",
            "Epochs(356/100) & Loss 135.65960693359375\n",
            "Epochs(357/100) & Loss 135.20101928710938\n",
            "Epochs(358/100) & Loss 134.74586486816406\n",
            "Epochs(359/100) & Loss 134.29425048828125\n",
            "Epochs(360/100) & Loss 133.84597778320312\n",
            "Epochs(361/100) & Loss 133.4009246826172\n",
            "Epochs(362/100) & Loss 132.9593048095703\n",
            "Epochs(363/100) & Loss 132.52084350585938\n",
            "Epochs(364/100) & Loss 132.08566284179688\n",
            "Epochs(365/100) & Loss 131.6537322998047\n",
            "Epochs(366/100) & Loss 131.22486877441406\n",
            "Epochs(367/100) & Loss 130.7992706298828\n",
            "Epochs(368/100) & Loss 130.37661743164062\n",
            "Epochs(369/100) & Loss 129.9571075439453\n",
            "Epochs(370/100) & Loss 129.54055786132812\n",
            "Epochs(371/100) & Loss 129.1270294189453\n",
            "Epochs(372/100) & Loss 128.71649169921875\n",
            "Epochs(373/100) & Loss 128.30880737304688\n",
            "Epochs(374/100) & Loss 127.9040298461914\n",
            "Epochs(375/100) & Loss 127.50211334228516\n",
            "Epochs(376/100) & Loss 127.10304260253906\n",
            "Epochs(377/100) & Loss 126.70671081542969\n",
            "Epochs(378/100) & Loss 126.31317138671875\n",
            "Epochs(379/100) & Loss 125.92244720458984\n",
            "Epochs(380/100) & Loss 125.5343246459961\n",
            "Epochs(381/100) & Loss 125.14884948730469\n",
            "Epochs(382/100) & Loss 124.76603698730469\n",
            "Epochs(383/100) & Loss 124.38582611083984\n",
            "Epochs(384/100) & Loss 124.00822448730469\n",
            "Epochs(385/100) & Loss 123.6331787109375\n",
            "Epochs(386/100) & Loss 123.2606201171875\n",
            "Epochs(387/100) & Loss 122.89057922363281\n",
            "Epochs(388/100) & Loss 122.5230484008789\n",
            "Epochs(389/100) & Loss 122.157958984375\n",
            "Epochs(390/100) & Loss 121.79521179199219\n",
            "Epochs(391/100) & Loss 121.43495178222656\n",
            "Epochs(392/100) & Loss 121.0770034790039\n",
            "Epochs(393/100) & Loss 120.72147369384766\n",
            "Epochs(394/100) & Loss 120.3681640625\n",
            "Epochs(395/100) & Loss 120.01705169677734\n",
            "Epochs(396/100) & Loss 119.6683578491211\n",
            "Epochs(397/100) & Loss 119.3218765258789\n",
            "Epochs(398/100) & Loss 118.97758483886719\n",
            "Epochs(399/100) & Loss 118.63543701171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShT9Hmj6XtR",
        "outputId": "05e7690a-7038-4a33-d9b4-e33f7086f131"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(118.2956, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezq8zGu6Xqs",
        "outputId": "84d89c3b-d6fc-4994-b142-103a688b0569"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.876376010176648"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvsKGPfB6XoH",
        "outputId": "f118eb33-590c-4d5e-acf4-7c6a7cba622b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 59.1970,  72.0904],\n",
              "        [ 75.3145,  94.5657],\n",
              "        [131.1051, 143.9752],\n",
              "        [ 31.1091,  47.5461],\n",
              "        [ 84.2706, 102.1874]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8284MJ6p5w",
        "outputId": "d56ee875-ecae-4993-ad14-6b7066ec1d9f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You can see they are almost close earch other"
      ],
      "metadata": {
        "id": "3jkj32ag6p3H"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network using Pytorch"
      ],
      "metadata": {
        "id": "6-OUXNOx3CPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "SHo8uHimkfNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d521bd18-8a65-45c3-b204-167c4ab2d3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  6 10:57:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# To check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jv4zRj3u3LtI"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swc3R2Ki3OSI",
        "outputId": "366a195e-aba5-4389-f7a6-6571878ddf3f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26421880/26421880 [00:02<00:00, 11637169.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 29515/29515 [00:00<00:00, 194545.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4422102/4422102 [00:01<00:00, 3639249.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5148/5148 [00:00<00:00, 7877518.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Cd71u_LZ3QMo",
        "outputId": "565e4314-cb5c-4556-e9c7-3cdfb1431082"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: str, train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 202);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8xEoct3Taa",
        "outputId": "278fc4fd-bb15-4cf7-f00f-e014e536931a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx_2V-C83aUS",
        "outputId": "2a05da6f-9048-4bb1-82aa-e3fc877d6e63"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZJS_-L3VQ4",
        "outputId": "a7c76430-3914-4c7c-e18d-1d18865bff02"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1SEEk4fz3ey2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "tryz3wtG3ewp"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "Z1C_N3if3j-j"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxIUc-Y3mSp",
        "outputId": "41ba4231-06f5-4610-c4cc-1c830eaea793"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301576  [    0/60000]\n",
            "loss: 2.293238  [ 6400/60000]\n",
            "loss: 2.281392  [12800/60000]\n",
            "loss: 2.274925  [19200/60000]\n",
            "loss: 2.248860  [25600/60000]\n",
            "loss: 2.231555  [32000/60000]\n",
            "loss: 2.239951  [38400/60000]\n",
            "loss: 2.208522  [44800/60000]\n",
            "loss: 2.204152  [51200/60000]\n",
            "loss: 2.185097  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.1%, Avg loss: 2.176164 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.183631  [    0/60000]\n",
            "loss: 2.174704  [ 6400/60000]\n",
            "loss: 2.128355  [12800/60000]\n",
            "loss: 2.141534  [19200/60000]\n",
            "loss: 2.094843  [25600/60000]\n",
            "loss: 2.042700  [32000/60000]\n",
            "loss: 2.076444  [38400/60000]\n",
            "loss: 2.001518  [44800/60000]\n",
            "loss: 2.001187  [51200/60000]\n",
            "loss: 1.947329  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 1.940534 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.966516  [    0/60000]\n",
            "loss: 1.939384  [ 6400/60000]\n",
            "loss: 1.836886  [12800/60000]\n",
            "loss: 1.873304  [19200/60000]\n",
            "loss: 1.770389  [25600/60000]\n",
            "loss: 1.717278  [32000/60000]\n",
            "loss: 1.747149  [38400/60000]\n",
            "loss: 1.640859  [44800/60000]\n",
            "loss: 1.659184  [51200/60000]\n",
            "loss: 1.564168  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.7%, Avg loss: 1.578085 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.635778  [    0/60000]\n",
            "loss: 1.597908  [ 6400/60000]\n",
            "loss: 1.458691  [12800/60000]\n",
            "loss: 1.527833  [19200/60000]\n",
            "loss: 1.410146  [25600/60000]\n",
            "loss: 1.396994  [32000/60000]\n",
            "loss: 1.412454  [38400/60000]\n",
            "loss: 1.328261  [44800/60000]\n",
            "loss: 1.364173  [51200/60000]\n",
            "loss: 1.261888  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.9%, Avg loss: 1.292733 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.367491  [    0/60000]\n",
            "loss: 1.339963  [ 6400/60000]\n",
            "loss: 1.188052  [12800/60000]\n",
            "loss: 1.288762  [19200/60000]\n",
            "loss: 1.169963  [25600/60000]\n",
            "loss: 1.187960  [32000/60000]\n",
            "loss: 1.203070  [38400/60000]\n",
            "loss: 1.133540  [44800/60000]\n",
            "loss: 1.178271  [51200/60000]\n",
            "loss: 1.087825  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 1.115184 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdoWByK3oxh",
        "outputId": "eb4d94aa-659d-46fd-d3ae-293419e2a228"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB0EWHe24DXZ",
        "outputId": "55e94445-785d-47a7-f348-d498694c5e08"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHA5ZZP4HEJ",
        "outputId": "ac04844e-dafa-48da-db0d-8f53e5e41c49"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "id": "7zvhooAy4KUJ",
        "outputId": "5f1e6877-81ce-482c-d713-25254693b8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9QxygE7G06c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}